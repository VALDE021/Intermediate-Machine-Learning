{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d59875-10ee-4dd5-8692-f7fe441b5547",
   "metadata": {},
   "source": [
    "# <u><center> Image Classification (Core)\n",
    "* Authored by: Eric N. Valdez\n",
    "* Date: 03-22-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcf5bb-3305-4f64-8604-a62ef105c3b2",
   "metadata": {},
   "source": [
    "# Assignment:\n",
    "- ## For this assignment, you will classify chest X-rays as \"normal,\" \"pneumonia,\" or \"covid\" using Convolutional Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b73741c-fdb2-4aef-a93b-4b6e68cd0200",
   "metadata": {},
   "source": [
    "# <u>Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55792b71-0dc4-4e8f-b8b6-ea7040da44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "# Set the seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import visualkeras as vk\n",
    "\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperParameters as hp\n",
    "\n",
    "folder = 'KerasTuner/'\n",
    "os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba883b3-b758-47a5-8fe7-c7483663ac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa6105-d3dd-40a2-bd62-d8b88bea780e",
   "metadata": {},
   "source": [
    "# <u>Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427d8486-df94-4a1b-b04f-f51f47006b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history, figsize=(6,12), marker='o'):\n",
    "       \n",
    "    # Get list of metrics from history\n",
    "    metrics = [c for c in history.history if not c.startswith('val_')]\n",
    "    \n",
    "    ## Separate row for each metric\n",
    "    fig, axes = plt.subplots(nrows=len(metrics),figsize=figsize)\n",
    "    \n",
    "    # For each metric\n",
    "    for i, metric_name in enumerate(metrics):\n",
    "    \n",
    "        # Get the axis for the current metric\n",
    "        ax = axes[i]\n",
    "    \n",
    "        # Get metric from history.history\n",
    "        metric_values = history.history[metric_name]\n",
    "        # Get epochs from history\n",
    "        epochs = history.epoch\n",
    "    \n",
    "        # Plot the training metric\n",
    "        ax.plot(epochs, metric_values, label=metric_name, marker=marker)\n",
    "    \n",
    "        ## Check if val_{metric} exists. if so, plot:\n",
    "        val_metric_name = f\"val_{metric_name}\"\n",
    "        if val_metric_name in history.history:\n",
    "            # Get validation values and plot\n",
    "            metric_values = history.history[val_metric_name]\n",
    "            ax.plot(epochs,metric_values,label=val_metric_name, marker=marker)\n",
    "    \n",
    "        # Final subplot adjustments \n",
    "        ax.legend()\n",
    "        ax.set_title(metric_name)\n",
    "    fig.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "def get_true_pred_labels(model,ds):\n",
    "    \"\"\"Gets the labels and predicted probabilities from a Tensorflow model and Dataset object.\n",
    "    Adapted from source: https://stackoverflow.com/questions/66386561/keras-classification-report-accuracy-is-different-between-model-predict-accurac\n",
    "    \"\"\"\n",
    "    y_true = []\n",
    "    y_pred_probs = []\n",
    "    \n",
    "    # Loop through the dataset as a numpy iterator\n",
    "    for images, labels in ds.as_numpy_iterator():\n",
    "        \n",
    "        # Get prediction with batch_size=1\n",
    "        y_probs = model.predict(images, batch_size=1, verbose=0)\n",
    "        # Combine previous labels/preds with new labels/preds\n",
    "        y_true.extend(labels)\n",
    "        y_pred_probs.extend(y_probs)\n",
    "    ## Convert the lists to arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred_probs = np.array(y_pred_probs)\n",
    "    \n",
    "    return y_true, y_pred_probs\n",
    "\n",
    "def convert_y_to_sklearn_classes(y, verbose=False):\n",
    "    # If already one-dimension\n",
    "    if np.ndim(y)==1:\n",
    "        if verbose:\n",
    "            print(\"- y is 1D, using it as-is.\")\n",
    "        return y\n",
    "        \n",
    "    # If 2 dimensions with more than 1 column:\n",
    "    elif y.shape[1]>1:\n",
    "        if verbose:\n",
    "            print(\"- y is 2D with >1 column. Using argmax for metrics.\")   \n",
    "        return np.argmax(y, axis=1)\n",
    "    \n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"y is 2D with 1 column. Using round for metrics.\")\n",
    "        return np.round(y).flatten().astype(int)\n",
    "\n",
    "## PREVIOUS CLASSIFICATION_METRICS FUNCTION FROM INTRO TO ML\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False,values_format=\".2f\",\n",
    "                           class_labels=None):\n",
    "    \"\"\"Modified version of classification metrics function from Intro to Machine Learning.\n",
    "    Updates:\n",
    "    - Reversed raw counts confusion matrix cmap  (so darker==more).\n",
    "    - Added arg for normalized confusion matrix values_format\n",
    "    \"\"\"\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels)\n",
    "    \n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    \n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    \n",
    "    # Create a confusion matrix  of raw counts (left subplot)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=None, \n",
    "                                            cmap='gist_gray_r',# Updated cmap\n",
    "                                            values_format=\"d\", \n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[0],\n",
    "                                           display_labels=class_labels);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "    \n",
    "    # Create a confusion matrix with the data with normalize argument \n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=normalize,\n",
    "                                            cmap=cmap, \n",
    "                                            values_format=values_format, #New arg\n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[1],\n",
    "                                            display_labels=class_labels);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    \n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True, target_names=class_labels)\n",
    "        return report_dict\n",
    "\n",
    "def evaluate_classification_network(model, \n",
    "                                    X_train=None, y_train=None, \n",
    "                                    X_test=None, y_test=None,\n",
    "                                    history=None, history_figsize=(6,6),\n",
    "                                    figsize=(6,4), normalize='true',\n",
    "                                    output_dict = False,\n",
    "                                    cmap_train='Blues',\n",
    "                                    cmap_test=\"Reds\",\n",
    "                                    values_format=\".2f\", \n",
    "                                    colorbar=False,\n",
    "                                    class_labels=None):\n",
    "    \"\"\"Evaluates a neural network classification task using either\n",
    "    separate X and y arrays or a tensorflow Dataset\n",
    "    \n",
    "    Data Args:\n",
    "        X_train (array, or Dataset)\n",
    "        y_train (array, or None if using a Dataset\n",
    "        X_test (array, or Dataset)\n",
    "        y_test (array, or None if using a Dataset)\n",
    "        history (history object)\n",
    "        \"\"\"\n",
    "    # Plot history, if provided\n",
    "    if history is not None:\n",
    "        plot_history(history, figsize=history_figsize)\n",
    "    ## Adding a Print Header\n",
    "    print(\"\\n\"+'='*80)\n",
    "    print('- Evaluating Network...')\n",
    "    print('='*80)\n",
    "    ## TRAINING DATA EVALUATION\n",
    "    # check if X_train was provided\n",
    "    if X_train is not None:\n",
    "        ## Check if X_train is a dataset\n",
    "        if hasattr(X_train,'map'):\n",
    "            # If it IS a Datset:\n",
    "            # extract y_train and y_train_pred with helper function\n",
    "            y_train, y_train_pred = get_true_pred_labels(model, X_train)\n",
    "        else:\n",
    "            # Get predictions for training data\n",
    "            y_train_pred = model.predict(X_train)\n",
    "        ## Pass both y-vars through helper compatibility function\n",
    "        y_train = convert_y_to_sklearn_classes(y_train)\n",
    "        y_train_pred = convert_y_to_sklearn_classes(y_train_pred)\n",
    "        \n",
    "        # Call the helper function to obtain regression metrics for training data\n",
    "        results_train = classification_metrics(y_train, y_train_pred, \n",
    "                                         output_dict=True, figsize=figsize,\n",
    "                                             colorbar=colorbar, cmap=cmap_train,\n",
    "                                               values_format=values_format,\n",
    "                                         label='Training Data',\n",
    "                                              class_labels=class_labels)\n",
    "        \n",
    "    \n",
    "\n",
    "    ## TEST DATA EVALUATION\n",
    "    # check if X_test was provided\n",
    "    if X_test is not None:\n",
    "        ## Check if X_train is a dataset\n",
    "        if hasattr(X_test,'map'):\n",
    "            # If it IS a Datset:\n",
    "            # extract y_train and y_train_pred with helper function\n",
    "            y_test, y_test_pred = get_true_pred_labels(model, X_test)\n",
    "        else:\n",
    "            # Get predictions for training data\n",
    "            y_test_pred = model.predict(X_test)\n",
    "        ## Pass both y-vars through helper compatibility function\n",
    "        y_test = convert_y_to_sklearn_classes(y_test)\n",
    "        y_test_pred = convert_y_to_sklearn_classes(y_test_pred)\n",
    "        \n",
    "        # Call the helper function to obtain regression metrics for training data\n",
    "        results_test = classification_metrics(y_test, y_test_pred, \n",
    "                                         output_dict=True, figsize=figsize,\n",
    "                                             colorbar=colorbar, cmap=cmap_test,\n",
    "                                              values_format=values_format,\n",
    "                                         label='Test Data',\n",
    "                                             class_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41677859-077c-4501-8985-d6635b9bd8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Infor from lec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf9fa00-002e-4fe2-b92c-973908168722",
   "metadata": {},
   "source": [
    "# <u>Making the TensorFlow Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b0ea31-818a-4712-92db-353a0a086784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/xrays/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the contents of dataset folder\n",
    "data_dir = \"Data/xrays/\"\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7558c791-d0b4-405b-b2ce-0c31710f9ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'covid']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gettting the list of folders from data dir\n",
    "subfolders = os.listdir(data_dir)\n",
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdec9b37-b0a2-4b58-9c05-7eaf58bf3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting the list of folders in the data_dir\n",
    "# os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dfd7f22-5061-44a0-b331-037bb321ddec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of all img file paths\n",
    "img_files = glob.glob(data_dir+\"**/*\")\n",
    "len(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1c79e5-6ca7-4c20-8ba6-161dca05e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving image params as vars for reuse\n",
    "batch_size = 32\n",
    "img_height = 96\n",
    "img_width = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b009f9-9b08-4eaf-84ea-bb8a2c605ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 495 files belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the dataset from the main folder of images\n",
    "ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "    shuffle=True,\n",
    "    label_mode='categorical',\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda12604-2bc2-4534-b5ea-ac0e3de06ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine number of batches in dataset\n",
    "ds_size = len(ds)\n",
    "ds_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74f791-b55d-4c0c-8c4e-47ac0471d202",
   "metadata": {},
   "source": [
    "## `Saving Class Info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3799111c-7ca8-484c-a85c-854f2c738836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'covid']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the class names for later use\n",
    "class_names = ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2696a190-b1d4-4518-92a0-2248f79856a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving # of classes for later use\n",
    "num_classes = len(class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a98b3ed-e574-40eb-ab65-0a2d8e7ba036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '.ipynb_checkpoints', 1: 'covid'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving dictionary of integer:string labels\n",
    "class_dict = dict(zip(range(num_classes), class_names))\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b26f1-c838-4242-b0e3-511a35f63296",
   "metadata": {},
   "source": [
    "## `Split the dataset into a training-validation-test split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabb7142-7120-4912-9da7-037fd9d379f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 11 batches as training data\n",
      "Use 3 batches as validation data\n",
      "The remaining 2 batches will be used as test data.\n"
     ]
    }
   ],
   "source": [
    "# Set the ratio of the train, validation, test split\n",
    "split_train = 0.7\n",
    "split_val = 0.2\n",
    "split_test = .1 \n",
    "# Calculate the number of batches for training and validation data \n",
    "n_train_batches =  int(ds_size * split_train)\n",
    "n_val_batches = int(ds_size * split_val)\n",
    "print(f\"Use {n_train_batches} batches as training data\")\n",
    "print(f\"Use {n_val_batches} batches as validation data\")\n",
    "print(f\"The remaining {len(ds)- (n_train_batches+n_val_batches)} batches will be used as test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1847b3f8-5180-4ad2-8aff-382625b4a67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set is 11 batches long.\n"
     ]
    }
   ],
   "source": [
    "# Use .take to slice out the number of batches \n",
    "train_ds = ds.take(n_train_batches)\n",
    "# Confirm the length of the training set\n",
    "print(f'The training set is {len(train_ds)} batches long.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b41978de-5c17-4b61-b554-f88b84aa0e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation set is 3 batches long.\n"
     ]
    }
   ],
   "source": [
    "# Skipover the training batches\n",
    "val_ds = ds.skip(n_train_batches)\n",
    "# Take the correct number of validation batches\n",
    "val_ds = val_ds.take(n_val_batches)\n",
    "# Confirm the length of the validation set\n",
    "print(f'The validation set is {len(val_ds)} batches long.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28fb00dc-b578-499f-8491-57b911c11622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set is 2 batches long.\n"
     ]
    }
   ],
   "source": [
    "# Skip over all of the training + validation batches\n",
    "test_ds = ds.skip(n_train_batches + n_val_batches)\n",
    "# Confirm the length of the testing data\n",
    "print(f'The testing set is {len(test_ds)} batches long.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7d8aa-c1e1-406c-9a46-1f8c63223731",
   "metadata": {},
   "source": [
    "# <u> `Optimize the Dataset`\n",
    "- ## Add a shuffle step to the training dataset\n",
    "- ## Add caching and prefetching to all 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8093ff-3dfd-4726-8bc0-7af197c03970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f3e7e1c-4430-418c-b7e4-123a040083b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use autotune to automatically determine best buffer sizes \n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Optimize training data\n",
    "train_ds = train_ds.cache().shuffle(buffer_size= len(train_ds),\n",
    "                                   seed=42).prefetch(buffer_size=AUTOTUNE)\n",
    "# Optimize validation data\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# Optimize teset data\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3236e3-1d52-45e1-a310-c7dfe7dca0e2",
   "metadata": {},
   "source": [
    "#  `Preview the Data and Save the Shape:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f03e2c9f-647e-4de9-8292-e0a1c2486f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 96, 96, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get image sizes for later use\n",
    "example_batch_imgs,example_batch_y= ds.take(1).get_single_element()\n",
    "example_batch_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a1af59f-1ebc-472a-a120-d76dc6ab67c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([96, 96, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Individual image shape\n",
    "input_shape = example_batch_imgs[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6125dd3-99e0-48eb-ad52-fc3ceb12112b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x96>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview an image from the Dataset\n",
    "array_to_img(example_batch_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d483207-83cc-45b1-be2a-7d20ae5289cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'covid'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show label value\n",
    "label = class_dict[np.argmax(example_batch_y[0])]\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb74ce42-6ea7-4019-b1e0-1cae6a25b9ef",
   "metadata": {},
   "source": [
    "# `Modeling`\n",
    "## <u>Modeling Steps (for every model):\n",
    "- ### **For every model**\n",
    "    - ### Fitting the Model\n",
    "        - using validation_data\n",
    "        - many epochs (20+)\n",
    "        - an EarlyStopping callback\n",
    "        - Save the training history \n",
    "- ### **Evaluating the Model:**\n",
    "    - ### Plot the training history\n",
    "    - ### Evaluating the model on the training and test data, including:\n",
    "        - Sckit-learning confusion matrix\n",
    "        - Sckit-learning classification Report\n",
    "        - The results from model.evaluate method\n",
    "            - (`Tip`: Use your custom flexible evaluation functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481679c-5539-4a31-b4f0-9d6bb51c9f7c",
   "metadata": {},
   "source": [
    "## `1) Build a Simple CNN Model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "427c53fe-0a41-45dd-a50f-0e939904eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get early stopping function that can be reused on all models\n",
    "def get_callbacks(patience=3, monitor='val_accuracy'):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=patience, monitor=monitor)\n",
    "    return [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f728334-aea8-4234-b7d5-79f61472596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the building and compiling steps within a function\n",
    "def build_model():\n",
    "    # Instantatie model\n",
    "    model = models.Sequential()\n",
    "    # Scaling layer\n",
    "    scaling_layer = layers.Rescaling(1./255, input_shape=input_shape)\n",
    "    model.add(scaling_layer)\n",
    "    \n",
    "    # Convolutional layer\n",
    "    model.add(layers.Conv2D(filters=8, kernel_size=3, input_shape=input_shape, padding='same')) \n",
    "    # Pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    # Convolutional layer\n",
    "    model.add(layers.Conv2D(filters=8, kernel_size=3, input_shape=input_shape, padding='same')) \n",
    "    # Pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    # Flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(3, activation=\"softmax\")) \n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5a230f8-fe4b-40c8-a3f8-bb5dbf9e1911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 96, 96, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 8)         224       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 13827     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,635\n",
      "Trainable params: 14,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model1 = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efe1d92b-c266-47c7-9c78-766934cb30f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 2) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filelymd0_5g.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\Valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 2) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs=25,\n",
    "    callbacks=get_callbacks(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076100f-41de-4919-92b0-c9808c22446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with the CNN + Dataset\n",
    "evaluate_classification_network(model1,\n",
    "                                X_train=train_ds,\n",
    "                                X_test=test_ds,\n",
    "                                figsize=(9,9),\n",
    "                                values_format='0.1f',\n",
    "                                history=history);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1dddff-1a31-4990-a348-f0aaba0191a6",
   "metadata": {},
   "source": [
    "**`Evaluation`**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91d35d-5be1-4973-b9d8-cfd9d0945f7f",
   "metadata": {},
   "source": [
    "## `2) Build a more complex CNN Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0785ad02-ab3d-4f30-a55e-f40b69c7672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the building and compiling steps within a function\n",
    "def build_model():\n",
    "    # Instantatie model\n",
    "    model = models.Sequential()\n",
    "    # Scaling layer\n",
    "    model.add(layers.Rescaling(1./255, input_shape=input_shape))\n",
    "    \n",
    "    # Convolutional layer - additional filters\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=3, input_shape=input_shape, padding='same')) \n",
    "    # Pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    # Convolutional layer - additional Conv2D\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=3, input_shape=input_shape, padding='same')) \n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=3, input_shape=input_shape, padding='same')) \n",
    "    # Pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Hidden dense layer\n",
    "    model.add(layers.Dense(32, activation=\"relu\"))\n",
    "    \n",
    "    # Flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(3, activation=\"softmax\")) \n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d368cda-cbb7-450e-9a01-a50a4a82e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model_2 = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66ce01-b334-46ea-a4a6-21aa55cf050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain and save history for examination\n",
    "history_2 = model_2.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs=25,\n",
    "    callbacks=get_callbacks(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa212f-10a8-4777-ad9e-8fd17bb1bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with the CNN + Dataset\n",
    "evaluate_classification_network(model_2,\n",
    "                                X_train=train_ds,\n",
    "                                X_test=test_ds,\n",
    "                                figsize=(9,9),\n",
    "                                values_format='0.1f',\n",
    "                                history=history_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2fba6-154a-4bec-b619-80890802b568",
   "metadata": {},
   "source": [
    "**`Evaluation`**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d1100-9122-4cb0-b028-fae2e21eca28",
   "metadata": {},
   "source": [
    "## `3) Build a Transfer Learning Model using a Keras Application`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c75a9-7c8d-4c2c-96fa-d9a205fba21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download base model\n",
    "inception_base= tf.keras.applications.InceptionV3(include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Make it not trainable\n",
    "inception_base.trainable=False\n",
    "vk.layered_view(inception_base, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d900f-09f3-4f7f-a0f7-167582e3f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add preprocessing lambda layer\n",
    "lambda_layer_inception = tf.keras.layers.Lambda(tf.keras.applications.inception_v3.preprocess_input, \n",
    "                                      name='preprocess_input_inceptv3')\n",
    "\n",
    "\n",
    "def build_inception_model():\n",
    "    model = models.Sequential(name=\"InceptionV3\")\n",
    "    # Use input layer (lambda layer will handle rescaling).\n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    ## Adding preprocessing lamabda layer\n",
    "    model.add(lambda_layer_inception)\n",
    "\n",
    "    # Add pretrained base\n",
    "    model.add(inception_base)\n",
    "\n",
    "    # Flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ## Adding a Hidden Dense Layer\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(len(class_names), activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dffcf43-6df3-4f90-be67-e8e15c3c1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build, fit, and evaluate EfficientNet Model\n",
    "model_inception = build_inception_model()\n",
    "history = model_inception.fit(train_ds, validation_data=val_ds,epochs=20, \n",
    "                    callbacks=get_callbacks()\n",
    "                   )\n",
    "evaluate_classification_network(model_inception, X_test=test_ds, history=history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300f821-bdd1-4c56-b21e-2230491a3831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29488e7-fae7-4784-816e-038b2dce976d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353b920-2184-4452-a98e-02641ea9830f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39117898-7dc8-4ee4-973c-33b0b201a792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3d28094-1ed8-4cf6-a70b-57dc8f28d9bb",
   "metadata": {},
   "source": [
    "**`Evaluation`**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f551a-ac65-472b-9ef0-278887b71c21",
   "metadata": {},
   "source": [
    "**`Choosing the Best Model`**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2632ee00-be80-4ad4-866a-8abd6d5d5eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8161f-15e2-44cf-9d5d-b4c80f04d251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc4b0d-7950-4b54-83e8-ccb27f0c6e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
