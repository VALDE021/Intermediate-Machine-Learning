{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72caa536-deec-4f00-bd5b-bc155175b311",
   "metadata": {},
   "source": [
    "## <u> Press the \"play\" button to train the network. Then, answer the following questions:\n",
    "\n",
    "## `1. Run the network. What do you notice?`\n",
    "   Not much, the epoch's are increasing and the output lines of both test and taining are the same perpendicular to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eef9d1-4a2e-4f7b-86a8-3b2b6704877a",
   "metadata": {},
   "source": [
    "## `2. Now, increase the number of neurons in the hidden layer and try changing the activation function to something other than \"Linear.\" Can you model the data now? How many neurons and what activation function allows you to effectively model the data?`\n",
    "### I added 5 to ReLU the output test loss is .23 training is .224\n",
    "### In Tanh its .501 and .500\n",
    "### In Sigmoid it gives the same results at Tanh\n",
    "### In Linear is the same at the other two\n",
    "### ReLu is the only change. As the Epoch increases the numbers go down "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd1f37-acc2-44bf-978a-102d383b313d",
   "metadata": {},
   "source": [
    "## `3. Feel free to add more neurons or layers or change anything you would like - can you model the data so that the testing loss is 0.01 or less? What is the smallest number of neurons and layers you can use that gives a test loss of 0.01 or less?`\n",
    "### Yes with 6 hidden layers and a learning rate of .1 in a ReLU avtivation, and no regularization but has a regularlization rate of 0.001 Problem type set at Classificaton and ratio training at 90% with 0 Noise and a Batch size of 15, and all my features feeding into the neuron layrers. My Output has gone 0.0000 for both test loss and training loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed8718e-a3e8-455d-adc3-be361cf95ecd",
   "metadata": {},
   "source": [
    "## `4. Play around with the learning rate. What do you notice? Based on this, what do you think the learning rate is?`\n",
    "### My learing rate is .1, no matter how many neurons I use from 1 to 6 the number can reach zero quick with only 100 or less epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
